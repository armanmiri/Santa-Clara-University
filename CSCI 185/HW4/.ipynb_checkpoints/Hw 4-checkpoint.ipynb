{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c852bb-1479-4726-9907-7b7be7207359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv('p2p-Gnutella04.txt', sep='\\t', comment='#', header=None, names=['FromNodeId', 'ToNodeId'])\n",
    "\n",
    "# Find all nodes with outgoing edges\n",
    "outgoing_nodes = set(data['FromNodeId'])\n",
    "\n",
    "# Find all nodes \n",
    "all_nodes = set(data['FromNodeId']).union(set(data['ToNodeId']))\n",
    "\n",
    "# Find sinks\n",
    "sinks = sorted(list(all_nodes - outgoing_nodes))\n",
    "\n",
    "# Write the result to sinks.csv\n",
    "sinks_df = pd.DataFrame(sinks, columns=['SinkNodeId'])\n",
    "sinks_df.to_csv('sinks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1527f35-8a7c-4dfe-b99a-f0624d870246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NodeId  PageRank\n",
      "0    1054  0.000367\n",
      "1    1536  0.000304\n",
      "2     171  0.000301\n",
      "3     453  0.000290\n",
      "4     407  0.000282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "damping_factor = 0.85\n",
    "num_iterations = 10\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv('p2p-Gnutella04.txt', sep='\\t', comment='#', header=None, names=['FromNodeId', 'ToNodeId'])\n",
    "\n",
    "# Identify all nodes\n",
    "all_nodes = set(data['FromNodeId']).union(set(data['ToNodeId']))\n",
    "num_nodes = len(all_nodes)\n",
    "\n",
    "# Initialize PageRank values\n",
    "pagerank = {node: 1 / num_nodes for node in all_nodes}\n",
    "\n",
    "# Create dictionaries for outgoing and incoming links for node\n",
    "outgoing_links = {node: [] for node in all_nodes}\n",
    "incoming_links = {node: [] for node in all_nodes}\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    outgoing_links[row['FromNodeId']].append(row['ToNodeId'])\n",
    "\n",
    "    incoming_links[row['ToNodeId']].append(row['FromNodeId'])\n",
    "\n",
    "# Function to remove sinks and update the edge list\n",
    "def remove_sinks(edges, all_nodes):\n",
    "    \n",
    "    sinks = [node for node in all_nodes if not outgoing_links[node]]\n",
    "    \n",
    "    for sink in sinks:\n",
    "        if sink in all_nodes:\n",
    "            all_nodes.remove(sink)\n",
    "    \n",
    "        if sink in outgoing_links:\n",
    "            outgoing_links.pop(sink)\n",
    "        \n",
    "        if sink in incoming_links:\n",
    "            incoming_links.pop(sink)\n",
    " \n",
    "\n",
    "    edges_no_sinks = [edge for edge in edges if edge['FromNodeId'] in all_nodes and edge['ToNodeId'] in all_nodes]\n",
    "    \n",
    "    return edges_no_sinks\n",
    "\n",
    "# Remove sinks and update edges\n",
    "edges_no_sinks = remove_sinks(data.to_dict('records'), all_nodes)\n",
    "\n",
    "# Assgining scores\n",
    "def page_rank(edges, all_nodes):\n",
    "    scores = {node: 1.0 / len(all_nodes) for node in all_nodes}\n",
    "    \n",
    "    incoming_links = {node: [] for node in all_nodes}\n",
    "    \n",
    "    for edge in edges:\n",
    "        source = edge['FromNodeId']\n",
    "        destination = edge['ToNodeId']\n",
    "        incoming_links[destination].append(source)\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        new_scores = {}\n",
    "    \n",
    "        for node in all_nodes:\n",
    "            incoming_sum = sum(scores[incoming] / len(outgoing_links[incoming]) for incoming in incoming_links[node])\n",
    "            new_scores[node] = (1 - damping_factor) / len(all_nodes) + damping_factor * incoming_sum\n",
    "        scores = new_scores\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Compute PageRank scores\n",
    "pagerank_scores = page_rank(edges_no_sinks, all_nodes)\n",
    "\n",
    "# Sort the scores by PageRank value in descending order\n",
    "sorted_pagerank = sorted(pagerank_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "pagerank_df = pd.DataFrame(sorted_pagerank, columns=['NodeId', 'PageRank'])\n",
    "\n",
    "# Write the result to PR_results.csv\n",
    "pagerank_df.to_csv('PR_results.csv', index=False)\n",
    "\n",
    "# Output the first few rows for verification\n",
    "print(pagerank_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3e2ad-531a-428e-b198-e3db43d6655b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
