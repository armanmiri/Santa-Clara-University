{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e41f7356-9d4e-4540-970d-7bf272a1d722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "def task1():\n",
    "\n",
    "    #define the list of integers\n",
    "    items = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    print(items)\n",
    "\n",
    "#calls to print\n",
    "task1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189cb2dc-6646-443c-8688-f409f49460dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items1: [1, 2, 3, 4, 5]\n",
      "items2: [6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def read_task2_data(filename):\n",
    "    try:\n",
    "        #open the filename in read mode\n",
    "        with open(filename, 'r') as file:\n",
    "\n",
    "            #access contents and remove spaces\n",
    "            data = file.read().strip()  \n",
    "\n",
    "        # store the items in their lists\n",
    "        items1 = [int(x) for x in data.split()[:5]]  \n",
    "\n",
    "        items2 = [int(x) for x in data.split()[5:]]  \n",
    "\n",
    "        return items1, items2\n",
    "\n",
    "    # if it cannot access gives error\n",
    "    except Error:\n",
    "        \n",
    "        print(\"Error!\")\n",
    "\n",
    "# read form the file for the lists data to check if its there\n",
    "items1, items2 = read_task2_data('task2.data')\n",
    "\n",
    "# print the lists\n",
    "print(\"items1:\", items1)\n",
    "\n",
    "print(\"items2:\", items2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b271328-4d33-4556-a638-504acbd8e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data using initialization:\n",
      "Using items():\n",
      "school: UAlbany\n",
      "address: 1400 Washington Ave, Albany, NY 12222\n",
      "phone: (518)442-3300\n",
      "\n",
      "Using keys():\n",
      "school: UAlbany\n",
      "address: 1400 Washington Ave, Albany, NY 12222\n",
      "phone: (518)442-3300\n",
      "\n",
      "Using values():\n",
      "UAlbany\n",
      "1400 Washington Ave, Albany, NY 12222\n",
      "(518)442-3300\n"
     ]
    }
   ],
   "source": [
    "def print_dictionary(data):\n",
    "\n",
    "    # using items to print\n",
    "    print(\"Using items():\")\n",
    "\n",
    "    # iterate and print the values in the key value pairs\n",
    "    for key, value in data.items():\n",
    "    \n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # using keys to print out\n",
    "    print(\"\\nUsing keys():\")\n",
    "\n",
    "    # iterate and print each key and its values\n",
    "    for key in data.keys():\n",
    "    \n",
    "        print(f\"{key}: {data[key]}\")\n",
    "\n",
    "    print(\"\\nUsing values():\")\n",
    "\n",
    "    # iterate and print the values in the dictionary\n",
    "    for value in data.values():\n",
    "    \n",
    "        print(value)\n",
    "\n",
    "# defined diction called data with the key value pairs\n",
    "data = {\n",
    "    'school': 'UAlbany',\n",
    "    'address': '1400 Washington Ave, Albany, NY 12222',\n",
    "    'phone': '(518)442-3300'\n",
    "}\n",
    "\n",
    "# printing the data \n",
    "print(\"Data using initialization:\")\n",
    "print_dictionary(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "991b97e4-7014-45a4-8ad3-b79897abf736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary stored in file 'data.json' successfully.\n",
      "\n",
      "Loaded dictionary:\n",
      "Using items():\n",
      "school: UAlbany\n",
      "address: 1400 Washington Ave, Albany, NY 12222\n",
      "phone: (518) 442-3300\n",
      "\n",
      "Using keys():\n",
      "school: UAlbany\n",
      "address: 1400 Washington Ave, Albany, NY 12222\n",
      "phone: (518) 442-3300\n",
      "\n",
      "Using values():\n",
      "UAlbany\n",
      "1400 Washington Ave, Albany, NY 12222\n",
      "(518) 442-3300\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def store_dict_to_file(data, filename):\n",
    "    try:\n",
    "        # open the file and try to print in the data dictionary\n",
    "        with open(filename, 'w') as file:\n",
    "        \n",
    "            json.dump(data, file)\n",
    "        \n",
    "        # sucess message \n",
    "        print(f\"Dictionary stored in file '{filename}' successfully.\")\n",
    "\n",
    "    # if it doesn't work error message\n",
    "    except:\n",
    "        \n",
    "        print(f\"Error.\")\n",
    "\n",
    "def load_dict_from_file(filename):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # open the file and load its contents to the dictionary\n",
    "        with open(filename, 'r') as file:\n",
    "        \n",
    "            data = json.load(file)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    # error if the file is not found\n",
    "    except Error:\n",
    "    \n",
    "        print(f\"Error!\")\n",
    "\n",
    "# data dictionary \n",
    "data = {\n",
    "    'school': 'UAlbany',\n",
    "    'address': '1400 Washington Ave, Albany, NY 12222',\n",
    "    'phone': '(518) 442-3300'\n",
    "}\n",
    "\n",
    "# store the data dictionary in the data.json file\n",
    "store_dict_to_file(data, 'data.json')\n",
    "\n",
    "loaded_data = load_dict_from_file('data.json')\n",
    "\n",
    "# check if the dictonary loaded right\n",
    "if loaded_data:\n",
    "\n",
    "    # prints dictionary\n",
    "    print(\"\\nLoaded dictionary:\")\n",
    "    \n",
    "    print_dictionary(loaded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38e7b63-b820-4200-8d38-3578bb177cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dumped to file 'task5.data'.\n",
      "Loaded data:\n",
      "List: [1, 2, 3, 4, 5]\n",
      "Dictionary: {'school': 'UAlbany', 'address': '1400 Washington Ave, Albany, NY 12222', 'phone': '(518) 442-3300'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def dump_to_file(data, filename):\n",
    "    #Dump data to a JSON file\n",
    "    try:\n",
    "        # opens file in write mode and \"dumps\" the data\n",
    "        with open(filename, 'w') as file:\n",
    "            \n",
    "            json.dump(data, file)\n",
    "\n",
    "        # success message\n",
    "        print(f\"Data dumped to file '{filename}'.\")\n",
    "\n",
    "    # error message for dumping\n",
    "    except:\n",
    "    \n",
    "        print(\"Error.\")\n",
    "\n",
    "def load_from_file(filename):\n",
    "    # loading data in read mode from file\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            \n",
    "            data = json.load(file)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    # error if file is not found\n",
    "    except Error:\n",
    "    \n",
    "        print(f\"Error.\")\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Define list and dictionary objects\n",
    "    items_list = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    data_dict = {\n",
    "        'school': 'UAlbany',\n",
    "        'address': '1400 Washington Ave, Albany, NY 12222',\n",
    "        'phone': '(518) 442-3300'\n",
    "    }\n",
    "\n",
    "    # Dump data to the file\n",
    "    dump_to_file({'list': items_list, 'dict': data_dict}, 'task5.data')\n",
    "\n",
    "    # Load data from the file\n",
    "    loaded_data = load_from_file('task5.data')\n",
    "\n",
    "    # Check if the data was loaded successfully\n",
    "    if loaded_data:\n",
    "        \n",
    "        # Print the loaded data\n",
    "        print(\"Loaded data:\")\n",
    "        \n",
    "        print(\"List:\", loaded_data['list'])\n",
    "        \n",
    "        print(\"Dictionary:\", loaded_data['dict'])\n",
    "\n",
    "# call the main funciton to print what is loaded\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "980ddb9b-1905-422b-bd02-2dea48a7c19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet IDs in CrimeReport.txt :\n",
      "Tweet ID: 429129916446031872\n",
      "Tweet ID: 429117247307923456\n",
      "Tweet ID: 429315798893461505\n",
      "Tweet ID: 429079910091476992\n",
      "Tweet ID: 429030956888899584\n",
      "Tweet ID: 429152645702352896\n",
      "Tweet ID: 429016075921940481\n",
      "Tweet ID: 428898232690044928\n",
      "Tweet ID: 428956892602191873\n",
      "Tweet ID: 429111068368326656\n",
      "Tweet ID: 429167217976958976\n",
      "Tweet ID: 429379822314614785\n",
      "Tweet ID: 429235096919359488\n",
      "Tweet ID: 428986795586383872\n",
      "Tweet ID: 429238790310203392\n",
      "Tweet ID: 429509723516194817\n",
      "Tweet ID: 429509617756811264\n",
      "Tweet ID: 429509135437017089\n",
      "Tweet ID: 429509033045659648\n",
      "Tweet ID: 429508763708817408\n",
      "Tweet ID: 429508217303875584\n",
      "Tweet ID: 429508122604883969\n",
      "Tweet ID: 429507949934157824\n",
      "Tweet ID: 429507930975510528\n",
      "Tweet ID: 429507700716613632\n",
      "Tweet ID: 429507388056412160\n",
      "Tweet ID: 429507387393703936\n",
      "Tweet ID: 429507291763576832\n",
      "Tweet ID: 429506469214437376\n",
      "Tweet ID: 429506433801924608\n",
      "Tweet ID: 429506012626702336\n",
      "Tweet ID: 429505339621662720\n",
      "Tweet ID: 429505236148174848\n",
      "Tweet ID: 429505189544878081\n",
      "Tweet ID: 429505128605818880\n",
      "Tweet ID: 429505116433956864\n",
      "Tweet ID: 429504618939158528\n",
      "Tweet ID: 429503319321493504\n",
      "Tweet ID: 429503199959986177\n",
      "Tweet ID: 429502545145237504\n",
      "Tweet ID: 429502437460680704\n",
      "Tweet ID: 429502289481449472\n",
      "Tweet ID: 429502207763836929\n",
      "Tweet ID: 429502122015481856\n",
      "Tweet ID: 429501723934461952\n",
      "Tweet ID: 429501695442186240\n",
      "Tweet ID: 429501574805585920\n",
      "Tweet ID: 429501521940598784\n",
      "Tweet ID: 429501272786354176\n",
      "Tweet ID: 429501173670739968\n",
      "Tweet ID: 429500659553931264\n",
      "Tweet ID: 429500626821996544\n",
      "Tweet ID: 429500250303111168\n",
      "Tweet ID: 429499974507061248\n",
      "Tweet ID: 429499957083897856\n",
      "Tweet ID: 429499927874789376\n",
      "Tweet ID: 429499891593658368\n",
      "Tweet ID: 429499566778351616\n",
      "Tweet ID: 429499480954531841\n",
      "Tweet ID: 429499000081760256\n",
      "Tweet ID: 429498405837369344\n",
      "Tweet ID: 429498397167734784\n",
      "Tweet ID: 429497948267765760\n",
      "Tweet ID: 429497921277415426\n",
      "Tweet ID: 429497098531115008\n",
      "Tweet ID: 429496907191181312\n",
      "Tweet ID: 429496260790206467\n",
      "Tweet ID: 429496119207272448\n",
      "Tweet ID: 429495848548847616\n",
      "Tweet ID: 429495195319951361\n",
      "Tweet ID: 429495172859060224\n",
      "Tweet ID: 429494325622222848\n",
      "Tweet ID: 429493745243799552\n",
      "Tweet ID: 429493724763389953\n",
      "Tweet ID: 429493689216679936\n",
      "Tweet ID: 429493026323300352\n",
      "Tweet ID: 429492585606807552\n",
      "Tweet ID: 429492578195472384\n",
      "Tweet ID: 429492510801420288\n",
      "Tweet ID: 429492212674478080\n",
      "Tweet ID: 429491944268374016\n",
      "Tweet ID: 429491406961250305\n",
      "Tweet ID: 429490875685556224\n",
      "Tweet ID: 429489676513054720\n",
      "Tweet ID: 429489649082314752\n",
      "Tweet ID: 429489638408220672\n",
      "Tweet ID: 429489636746878976\n",
      "Tweet ID: 429489636444884992\n",
      "Tweet ID: 429489636423897090\n",
      "Tweet ID: 429489636386144256\n",
      "Tweet ID: 429489380147740672\n",
      "Tweet ID: 429488933169147904\n",
      "Tweet ID: 429488616197193730\n",
      "Tweet ID: 429488467572056064\n",
      "Tweet ID: 429488175862808576\n",
      "Tweet ID: 429488126608678912\n",
      "Tweet ID: 429487461878992897\n",
      "Tweet ID: 429487155757330432\n",
      "Tweet ID: 429487042423033856\n",
      "Tweet ID: 429486947955146752\n",
      "Tweet ID: 429486365659906048\n",
      "Tweet ID: 429485718771990528\n",
      "Tweet ID: 429485563507654656\n",
      "Tweet ID: 429485059242856448\n",
      "Tweet ID: 429484915839991808\n",
      "Tweet ID: 429484743227625472\n",
      "Tweet ID: 429484226082525184\n",
      "Tweet ID: 429484187171971072\n",
      "Tweet ID: 429483997932949504\n",
      "Tweet ID: 429483743066091521\n",
      "Tweet ID: 429483488165654528\n",
      "Tweet ID: 429482862300397568\n",
      "Tweet ID: 429482630036205568\n",
      "Tweet ID: 429482200552067073\n",
      "Tweet ID: 429482178645606400\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def print_tweet_ids(filename):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # Open the file and read the tweets\n",
    "        with open(filename, 'r') as file:\n",
    "        \n",
    "            tweets = file.readlines()\n",
    "\n",
    "        # Iterate through each tweet\n",
    "        for tweet_json in tweets:\n",
    "            \n",
    "            # convert each tweet to the pthon dictionary format\n",
    "            tweet = json.loads(tweet_json)\n",
    "            \n",
    "            # Extract and print the tweet ID\n",
    "            tweet_id = tweet.get('id')\n",
    "            \n",
    "            if tweet_id:\n",
    "            \n",
    "                print(\"Tweet ID:\", tweet_id)\n",
    "            \n",
    "            else:\n",
    "\n",
    "                print(\"Tweet ID not found for this tweet.\")\n",
    "\n",
    "    # error if file is not ofund\n",
    "    except Error:\n",
    "        \n",
    "        print(f\"Error\")\n",
    "\n",
    "# the filename containting tweets\n",
    "filename = \"CrimeReport.txt\"\n",
    "\n",
    "# Print the IDs of tweets in the file calling function\n",
    "print(\"Tweet IDs in\", filename, \":\")\n",
    "\n",
    "print_tweet_ids(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da2ad43f-b65c-4859-be19-d7f6afb05629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 recent tweets saved to 'task7.data'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def filter_recent_tweets(input_filename, output_filename, num_tweets=10):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # Open the input file and read its contents\n",
    "        with open(input_filename, 'r') as file:\n",
    "            tweets = file.readlines()\n",
    "\n",
    "        # Convert each tweet from JSON format to a Python dictionary\n",
    "        tweets_data = [json.loads(tweet) for tweet in tweets]\n",
    "\n",
    "        # Sort the tweets based on their creation time \n",
    "        sorted_tweets = sorted(tweets_data, key=lambda x: x.get('created_at'))\n",
    "\n",
    "        # Select the 10 most recent tweets\n",
    "        recent_tweets = sorted_tweets[-num_tweets:]\n",
    "\n",
    "        # Write the recent tweets to the output file\n",
    "        with open(output_filename, 'w') as file:\n",
    "            \n",
    "            for tweet in recent_tweets:\n",
    "            \n",
    "                file.write(json.dumps(tweet) + '\\n')\n",
    "\n",
    "        print(f\"{num_tweets} recent tweets saved to '{output_filename}'.\")\n",
    "    \n",
    "    # error if file is not found\n",
    "    except Error:\n",
    "        \n",
    "        print(f\"Errror\")\n",
    "\n",
    "# Specify the input and output filenames\n",
    "input_filename = \"CrimeReport.txt\"\n",
    "\n",
    "output_filename = \"task7.data\"\n",
    "\n",
    "# Filter and save the 10 most recent tweets\n",
    "filter_recent_tweets(input_filename, output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e269fda-b621-4b0c-8f25-e4758bfb0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets separated stored in the output folder.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def separate_tweets_by_hour(input_filename, output_folder):\n",
    "\n",
    "    try:\n",
    "        # Create the output folder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "    \n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Open the input file and read its contents\n",
    "        with open(input_filename, 'r') as file:\n",
    "            \n",
    "            tweets = file.readlines()\n",
    "\n",
    "        # Convert each tweet from JSON format to a Python dictionary\n",
    "        tweets_data = [json.loads(tweet) for tweet in tweets]\n",
    "\n",
    "        # Group tweets by hour\n",
    "        tweet_groups = {}\n",
    "        \n",
    "        for tweet in tweets_data:\n",
    "        \n",
    "            # Extract the creation time of the tweet\n",
    "            created_at = tweet.get('created_at')\n",
    "            \n",
    "            if created_at:\n",
    "            \n",
    "                # convert the creation time into a datetime object\n",
    "                created_time = datetime.strptime(created_at, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "                \n",
    "                # Extract the hour component\n",
    "                hour = created_time.strftime(\"%Y-%m-%d-%H\")\n",
    "                \n",
    "                # Add the tweet to the corresponding hour group\n",
    "                if hour not in tweet_groups:\n",
    "                \n",
    "                    tweet_groups[hour] = []\n",
    "                \n",
    "                tweet_groups[hour].append(tweet)\n",
    "\n",
    "        # Write tweets to separate files for each hour group\n",
    "        for hour, tweets_in_hour in tweet_groups.items():\n",
    "           \n",
    "            output_filename = os.path.join(output_folder, f\"{hour}.txt\")\n",
    "            \n",
    "            with open(output_filename, 'w') as file:\n",
    "            \n",
    "                for tweet in tweets_in_hour:\n",
    "                \n",
    "                    file.write(json.dumps(tweet) + '\\n')\n",
    "\n",
    "        print(\"Tweets separated stored in the output folder.\")\n",
    "\n",
    "    \n",
    "    except Error:\n",
    "       \n",
    "        print(f\"Error\")\n",
    "\n",
    "# Specify the input filename and output folder\n",
    "input_filename = \"CrimeReport.txt\"\n",
    "output_folder = \"task8-output\"\n",
    "\n",
    "# Separate tweets by hour and store them in separate files\n",
    "separate_tweets_by_hour(input_filename, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
